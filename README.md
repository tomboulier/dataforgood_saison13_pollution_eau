# Rendre Visible la Pollution de l'Eau Potable üíß

## Contexte du Projet

Ce projet, d√©velopp√© par des b√©n√©voles de [Data For Good](https://www.dataforgood.fr/) lors de la saison 13, vise √† cr√©er une carte interactive pour [G√©n√©rations Futures](https://www.generations-futures.fr/).

L'objectif est de consolider, analyser et cartographier les donn√©es sur la qualit√© de l'eau potable en France √† partir de sources de donn√©es ouvertes.

## Structure du Projet

- `pipelines/` : Consolidation et pr√©paration des donn√©es
- `analytics/` : Analyse des donn√©es
- `webapp/` : D√©veloppement du site web interactif

## Installation

### Data Pipelines

- [Installation de Python](#installation-de-python)

Ce projet utilise [uv](https://docs.astral.sh/uv/) pour la gestion des d√©pendances Python. Il est pr√©r√©quis pour l'installation de ce projet.

Installation sur Windows

```bash
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

Installation sur Mac ou linux

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Une fois install√©, il suffit de lancer la commande suivante pour installer la version de Python ad√©quate, cr√©er un environnement virtuel et installer les d√©pendances du projet.

```bash
uv sync
```

#### VSCode

A l'usage, si vous utilisez VSCode, l'environnement virtuel sera automatiquement activ√© lorsque vous ouvrirez le projet. Sinon, il suffit de l'activer manuellement avec la commande suivante :

```bash
source .venv/bin/activate
```

Ou alors, utilisez la commande `uv run ...` (au lieu de `python ...`) pour lancer un script Python. Par exemple:

```bash
uv run pipelines/run.py run build_database
```

#### Pycharm

Allez dans settings, python interpreter, add interpreter, puis selectionnez existing venv et allez chercher le path du python executable dans .venv (.venv/Scripts/Python.exe pour windows)

#### Terminal

utilisez les commandes `uv run` pour lancer un script Python depuis votre terminal

- [Installation de Node.js](#installation-de-nodejs) (pour le d√©veloppement du site web et pour l'usage de Evidence)

Pour le d√©veloppement du site web et pour l'usage de [Evidence](https://evidence.dev/), il est n√©cessaire d'installer Node.js. Pour cela, il suffit de suivre les instructions sur le [site officiel](https://nodejs.org/).

Pour installer les d√©pendances du site web, il suffit de lancer les commandes suivantes :

```bash
cd webapp
npm install
```

## Data Processing

### Package installation

Tout le code dans pipelines sera install√© en tant que package python automatiquement √† chaque uv_sync

### Comment construire la database

Une fois l'environnement python setup avec uv, vous pouvez lancer data_pipeline/run.py pour remplir la database
Il suffit de lancer

```bash
uv run pipelines/run.py run build_database
```

### Connection a Scaleway via boto3 pour stockage cloud

Un utils a √©t√© cr√©√© dans [storage_client.py](pipelines%2Futils%2Fstorage_client.py) pour faciliter la connection au S3 h√©berg√© sur Scaleway.

Il faut cr√©er un fichier .env dans le dossier pipelines/config avec les secrets ci dessous dedans pour que la connection fonctionne.

```text
SCW_ACCESS_KEY={ACCESS_KEY}
SCW_SECRET_KEY={SECRET_KEY}
```

Vous trouverez un example avec le fichier [.env.example](pipelines%2Fconfig%2F.env.example)

> ‚ö† **Attention:** Ne jamais commir les access key et secret key.

Un vaultwarden va √™tre setup pour r√©cup√©rer les secrets pour les personnes qui en ont besoin

Le notebook [test_storage_utils.ipynb](pipelines%2Fnotebooks%2Ftest_storage_utils.ipynb) montre un example d'utilisation de l'utils pour charger et lire des csv sur le bucket S3 du projet

### Data analysis

Les analyses ce font via jupyter notebook

```bash
uv run jupyter notebook
```

## Pre Commit

Lancer la commande suivante pour s'assurer que le code satisfait bien tous les pre commit avant de cr√©er votre pull request

```ba*sh
pre-commit run --all-files
```
